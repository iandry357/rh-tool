version: '3.8'

services:
  postgres:
    image: pgvector/pgvector:pg16
    container_name: rh_postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - ./data/postgres:/var/lib/postgresql/data
    ports:
      - "${POSTGRES_PORT}:5432"
    networks:
      - rh_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5

  backend:
    build: ./backend
    container_name: rh_backend
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:5432/${POSTGRES_DB}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY}
    volumes:
      - ./backend:/app
    ports:
      - "${BACKEND_PORT}:8000"
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - rh_network
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

  # frontend:
  #   build: ./frontend
  #   container_name: rh_frontend
  #   environment:
  #     NEXT_PUBLIC_API_URL: ${NEXT_PUBLIC_API_URL}
  #   volumes:
  #     - ./frontend:/app
  #     - /app/node_modules
  #     - /app/.next
  #   ports:
  #     - "${FRONTEND_PORT}:3000"
  #   depends_on:
  #     - backend
  #   networks:
  #     - rh_network
  #   command: npm run dev

  # Optionnel: Ollama pour LLM local
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: rh_ollama
  #   volumes:
  #     - ./data/ollama:/root/.ollama
  #   ports:
  #     - "11434:11434"
  #   networks:
  #     - rh_network

networks:
  rh_network:
    driver: bridge